

Section 17, Lecture 84
Improving and Tuning the RNN - Homework Challenge

As we saw in the previous section, the issue of our previous RNN model was in the one unit timestep. Because the timestep was 1, the model didn't learn anything useful, because it only took into account the input stock price at time t. Therefore, the model needs more past info to look back when predicting the stock price at time t+1. So instead of only looking at the stock price at time t, we want for example our model to look back at the stock prices at times t-20, t-19, ..., and t-1. In that last example the timestep is 20. And we still predict the stock price for the next day, that is here the stock price at time t. 

Therefore the challenge now is to improve the model by increasing the timestep.

Besides we will also try to improve our model by adding more LSTM layers.

Hence, here are the Homework Instructions:

Make four models:

 1. Model 1 - 20 timesteps & 1 LSTM layer
 2. Model 2 - 20 timesteps & 4 LSTM layers
 3. Model 3 - 60 timesteps & 1 LSTM layer
 4. Model 4 - 60 timesteps & 4 STM layers

Plot your results (real stock price and predicted stock price of January 2017) on a same chart.

Optional: you can do some Parameter Tuning on these four models. Parameter Tuning for Regression is the same as Parameter Tuning for Classification which you learned in Part 1 - Artificial Neural Networks, only here for Regression you have to replace scoring = 'accuracy'  by scoring = 'mse' in the GridSearchCV class parameters.

And eventually, feel free to create another architecture of the RNN model or even take a whole new approach of the problem if you think there is a better one, we'd be very happy to see your results in the Q&A.

Enjoy Deep Learning!